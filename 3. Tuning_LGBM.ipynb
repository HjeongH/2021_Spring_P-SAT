{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM 하이퍼파라미터 튜닝\n",
    "### 강아지, catboost 인코딩 튜닝코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMModel,LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import scipy.stats as ss\n",
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMModel,LGBMClassifier\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score\n",
    "from statistics import *\n",
    "\n",
    "\n",
    "os.chdir(\"C:/Users/hjh05/Downloads/ugi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train튜닝 (ver. 캣부스트 인코딩)\n",
    "#### 추가 파라미터 튜닝 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dog=pd.read_csv('data/final_train_dog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adoptionYN      category\n",
      "weight_kg        float64\n",
      "neuterYN          object\n",
      "sex               object\n",
      "positives          int64\n",
      "negatives          int64\n",
      "group_akc         object\n",
      "grdp             float64\n",
      "economy          float64\n",
      "hospital_num       int64\n",
      "color             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#범주형 변환 adoptionYN, neuterYN, sex, group_akc, color\n",
    "train_dog['adoptionYN'] = train_dog['adoptionYN'].astype('category')\n",
    "cols = ['neuterYN','sex','group_akc','color']\n",
    "for col in cols:\n",
    "    train_dog[col] = train_dog[col].astype('object')\n",
    "print (train_dog.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = train_dog.drop(['adoptionYN'],axis=1)\n",
    "y_data= train_dog['adoptionYN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fold 나누기\n",
    "folds = StratifiedKFold(n_splits=5, random_state=613)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########수정필\n",
    "#파라미터 튜닝용 df!!\n",
    "learning_rates = np.array([0.05, 0.1, 0.3, 0.5, 0.7, 0.99])\n",
    "num_leaves = np.array([15, 31, 63, 127, 255, 511])\n",
    "max_depth = np.array([3, 12])\n",
    "\n",
    "par= pd.DataFrame(list(product(*[learning_rates, num_leaves,max_depth])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "### 코드\n",
    "acc=[]\n",
    "f1score=[]\n",
    "\n",
    "for i in tqdm(range(0,len(par))):\n",
    "    acc_here=[]\n",
    "    f1score_here=[]\n",
    "\n",
    "    for train_index, val_index in folds.split(x_data, y_data):\n",
    "        x_train, x_val = x_data.iloc[train_index], x_data.iloc[val_index]\n",
    "        y_train, y_val = y_data.iloc[train_index], y_data.iloc[val_index]\n",
    "    \n",
    "        #scaling\n",
    "        scaled_x_train = x_train\n",
    "        scaled_x_val = x_val\n",
    "\n",
    "        scaler.fit(x_train[['weight_kg', 'positives', 'negatives', 'grdp', 'economy','hospital_num']])\n",
    "        scaled_x_train[['weight_kg', 'positives', 'negatives', 'grdp', 'economy','hospital_num']] = scaler.transform(scaled_x_train[['weight_kg', 'positives', 'negatives', 'grdp', 'economy','hospital_num']])\n",
    "        scaled_x_val[['weight_kg', 'positives', 'negatives', 'grdp', 'economy','hospital_num']] = scaler.transform(scaled_x_val[['weight_kg', 'positives', 'negatives', 'grdp', 'economy','hospital_num']])\n",
    "\n",
    "        #encoding?\n",
    "        feature_list = list(scaled_x_train.columns)\n",
    "        CBE_encoder = CatBoostEncoder()\n",
    "        tuned_x_train = CBE_encoder.fit_transform(scaled_x_train[feature_list], y_train)\n",
    "        tuned_x_val = CBE_encoder.transform(scaled_x_val[feature_list])\n",
    "        \n",
    "        #학습\n",
    "        lgbm_ml = LGBMClassifier(learning_rate = par.iloc[i,0],\n",
    "              num_leaves=par.iloc[i,1],\n",
    "            max_depth=par.iloc[i,2],\n",
    "              random_state=613)\n",
    "        \n",
    "        lgbm_ml.fit(tuned_x_train, y_train)\n",
    "\n",
    "        #prediction\n",
    "        y_pred = lgbm_ml.predict(tuned_x_val)\n",
    "        y_pred[y_pred>=0.5]=1\n",
    "        y_pred[y_pred<0.5]=0\n",
    "        \n",
    "        acc1 = accuracy_score(y_val, y_pred)\n",
    "        acc_here.append(acc1)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        f1score_here.append(f1)\n",
    "        \n",
    "    acc.append(np.mean(acc_here))\n",
    "    f1score.append(np.mean(f1score_here))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.10</td>\n",
       "      <td>127</td>\n",
       "      <td>12</td>\n",
       "      <td>0.740018</td>\n",
       "      <td>0.608960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.10</td>\n",
       "      <td>63</td>\n",
       "      <td>12</td>\n",
       "      <td>0.743898</td>\n",
       "      <td>0.607881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.05</td>\n",
       "      <td>127</td>\n",
       "      <td>12</td>\n",
       "      <td>0.743773</td>\n",
       "      <td>0.607007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.10</td>\n",
       "      <td>255</td>\n",
       "      <td>12</td>\n",
       "      <td>0.736209</td>\n",
       "      <td>0.606766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.10</td>\n",
       "      <td>511</td>\n",
       "      <td>12</td>\n",
       "      <td>0.736477</td>\n",
       "      <td>0.605636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1   2       acc   f1score\n",
       "19  0.10  127  12  0.740018  0.608960\n",
       "17  0.10   63  12  0.743898  0.607881\n",
       "7   0.05  127  12  0.743773  0.607007\n",
       "21  0.10  255  12  0.736209  0.606766\n",
       "23  0.10  511  12  0.736477  0.605636"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과확인\n",
    "par['acc']=acc\n",
    "par['f1score'] = f1score\n",
    "\n",
    "par.sort_values(by=['f1score'], axis=0, ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#par.to_csv('lgbm_dog_ctb.csv', index=False, header=True,encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  test에 결과 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dog=pd.read_csv('data/final_train_dog.csv')\n",
    "test_dog=pd.read_csv('data/final_test_dog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adoptionYN      category\n",
      "weight_kg        float64\n",
      "neuterYN          object\n",
      "sex               object\n",
      "positives          int64\n",
      "negatives          int64\n",
      "group_akc         object\n",
      "grdp             float64\n",
      "economy          float64\n",
      "hospital_num       int64\n",
      "color             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#train 범주형 변환 adoptionYN, neuterYN, sex, group_akc, color\n",
    "train_dog['adoptionYN'] = train_dog['adoptionYN'].astype('category')\n",
    "cols = ['neuterYN','sex','group_akc','color']\n",
    "for col in cols:\n",
    "    train_dog[col] = train_dog[col].astype('object')\n",
    "print (train_dog.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test 범주형 변환 adoptionYN, neuterYN, sex, group_akc, color\n",
    "test_dog['adoptionYN'] = test_dog['adoptionYN'].astype('category')\n",
    "test_dog['neuterYN'] = test_dog['neuterYN'].astype('object')\n",
    "test_dog['sex'] = test_dog['sex'].astype('object')\n",
    "test_dog['group_akc'] = test_dog['group_akc'].astype('object')\n",
    "test_dog['color'] = test_dog['color'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_dog.drop(['adoptionYN'],axis=1)\n",
    "y_train= train_dog['adoptionYN']\n",
    "\n",
    "x_test = test_dog.drop(['adoptionYN'],axis=1)\n",
    "y_test= test_dog['adoptionYN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train 스케일링\n",
    "scaler.fit(x_train[['weight_kg', 'positives', 'negatives', 'grdp', 'economy','hospital_num']])\n",
    "x_train[['weight_kg', 'positives', 'negatives', 'grdp', 'economy','hospital_num']] = scaler.transform(x_train[['weight_kg', 'positives', 'negatives', 'grdp', 'economy','hospital_num']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test 스케일링\n",
    "scaler.fit(x_test[['weight_kg', 'positives', 'negatives', 'grdp', 'economy','hospital_num']])\n",
    "x_test[['weight_kg', 'positives', 'negatives', 'grdp', 'economy','hospital_num']] = scaler.transform(x_test[['weight_kg', 'positives', 'negatives', 'grdp', 'economy','hospital_num']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#인코딩\n",
    "feature_list = list(x_train.columns)\n",
    "CBE_encoder = CatBoostEncoder()\n",
    "train_cbe = CBE_encoder.fit_transform(x_train[feature_list], y_train)\n",
    "test_cbe = CBE_encoder.transform(x_test[feature_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(max_depth=12, num_leaves=127, random_state=613)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#적합\n",
    "lgbm_ml = LGBMClassifier(learning_rate = 0.10, num_leaves=127, max_depth=12, random_state=613)        \n",
    "lgbm_ml.fit(train_cbe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6195717191051562\n",
      "0.7346461949265688\n"
     ]
    }
   ],
   "source": [
    "#예측\n",
    "y_pred = lgbm_ml.predict(test_cbe)\n",
    "y_pred[y_pred>=0.5]=1\n",
    "y_pred[y_pred<0.5]=0\n",
    "\n",
    "        \n",
    "print(f1_score(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
